# BERT Tokenizer and Encoder

This project demonstrates how to tokenize and encode text using the pre-trained BERT model (`bert-base-uncased`) from Hugging Face.

## Features
- Tokenizes text into subwords
- Converts tokens into numerical IDs
- Uses Hugging Face Transformers

## Files
- `bert_tokenizer_encoder.ipynb`: Main Jupyter Notebook
- `requirements.txt`: Required packages

## Example

**Input Text:**

**Tokens:**

**Token IDs:**

## Installation

Run notebook via Jupyter or Google Colab.
